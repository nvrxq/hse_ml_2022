{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxwOUXsBA7N6"
      },
      "source": [
        "### Машинное обучение\n",
        "## Домашнее задание №3 - Градиентный бустинг"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nnb6L4XbA7N8"
      },
      "source": [
        "**Общая информация**\n",
        "\n",
        "**Срок сдачи:** 16 февраля 2023, 08:30   \n",
        "**Штраф за опоздание:** -2 балла за каждые сутки\n",
        "\n",
        "Используйте данный Ipython Notebook при оформлении домашнего задания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOfGe85vA7N9"
      },
      "source": [
        "##  Считаем производные для функций потерь (1 балл)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MOTkXLJA7N9"
      },
      "source": [
        "Мы будем реализовать градиентный бустинг для 3 функций потерь:\n",
        "\n",
        "1) MSE  $L(a(x_i), y_i) = (y_i - a(x_i)) ^ 2$\n",
        "\n",
        "2) Экспоненциальная  $L(a(x_i), y_i) = exp( -a(x_i) y_i), y_i \\in \\{-1, 1\\}$\n",
        "\n",
        "3) Логистическая  $L(a(x_i), y_i) = \\log (1 + exp( -a(x_i) y_i)), y_i \\in \\{-1, 1\\}$\n",
        "\n",
        "где $a(x_i)$ предсказание бустинга на итом объекте. \n",
        "\n",
        "Для каждой функции потерь напишите таргет, на который будет настраиваться каждое дерево в бустинге. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1a_m5WeA7N-"
      },
      "source": [
        "Ваше решение тут"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx6deysjA7N-"
      },
      "source": [
        "1)mse : $$2 *(y - a)$$\n",
        "2)exp : $$\\exp(-a(x)y) * y $$\n",
        "3)logloss : $$\\frac{1}{1 + \\exp(-a(x)y)} * (exp(-a(xi)y) * y)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O6s_gZsA7N_"
      },
      "source": [
        "##  Реализуем градиентный бустинг (3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LB5WZ9UaA7N_"
      },
      "source": [
        "Реализуйте класс градиентного бустинга для классификации. Ваша реализация бустинга должна работать по точности не более чем на 5 процентов хуже чем GradientBoostingClassifier из sklearn. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc8vCbKJA7OA"
      },
      "source": [
        "Детали реализации:\n",
        "\n",
        "-- должно поддерживаться 3 функции потерь\n",
        "\n",
        "-- сами базовые алгоритмы(деревья, линейные модели и тп) реализовать не надо, просто возьмите готовые из sklearn\n",
        "\n",
        "-- в качестве функции потерь для построения одного дерева используйте MSE\n",
        "\n",
        "-- шаг в бустинге можно не подбирать, можно брать константный\n",
        "\n",
        "-- можно брать разные модели в качестве инициализации бустинга\n",
        "\n",
        "-- должны поддерживаться следующие параметры:\n",
        "\n",
        "а) число итераций\n",
        "б) размер шага\n",
        "в) процент случайных фичей при построении одного дерева\n",
        "д) процент случайных объектов при построении одного дерева\n",
        "е) параметры базового алгоритма (передавайте через **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "collapsed": true,
        "id": "ts0v-wnQA7OB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from random import sample\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "collapsed": true,
        "id": "wtZdl2A0A7OB"
      },
      "outputs": [],
      "source": [
        "class MyGradientBoostingClassifier:\n",
        "\n",
        "    def __init__(self, loss='mse', \n",
        "                 learning_rate=0.1, \n",
        "                 n_estimators=50, \n",
        "                 colsample=1.0, \n",
        "                 subsample=1.0, \n",
        "                 *args, **kwargs):\n",
        "        \"\"\"\n",
        "        loss -- один из 3 лоссов:\n",
        "        learning_rate -- шаг бустинга\n",
        "        n_estimators -- число итераций\n",
        "        colsample -- процент рандомных признаков при обучнеии одного алгоритма\n",
        "        subsample -- процент рандомных объектов при обучнеии одного алгоритма\n",
        "        args, kwargs -- параметры  базовых моделей\n",
        "        \"\"\"\n",
        "        # Ваш код здесь\n",
        "        self.loss = loss\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_estimators = n_estimators\n",
        "        self.colsample = colsample\n",
        "        self.subsample = subsample\n",
        "        self.args = args\n",
        "        self.kwargs = kwargs\n",
        "        self.losses_dict = {\n",
        "            'mse' : self.mse_grad,\n",
        "            'exploss' : self.exp_grad,\n",
        "            'logloss' : self.logLoss_grad\n",
        "        }\n",
        "    \n",
        "\n",
        "    def mse_grad(self, y_true, y_pred):\n",
        "      return 2 * (y_true - y_pred)\n",
        "\n",
        "    def exp_grad(self, y_true, y_pred):\n",
        "      return np.exp(y_true * -y_pred) * y_true\n",
        "      \n",
        "   \n",
        "    def logLoss_grad(self, y_true, y_pred):\n",
        "      d1 = np.exp(-y_pred * y_true) \n",
        "      return (d1 * y_true) / (1 + d1)\n",
        "\n",
        "\n",
        "    def fit(self, X, y, base_model = DecisionTreeRegressor, init_model=None):\n",
        "        \"\"\"\n",
        "        X -- объекты для обучения:\n",
        "        y -- таргеты для обучения\n",
        "        base_model -- класс базовых моделей, например sklearn.tree.DecisionTreeRegressor\n",
        "        init_model -- класс для первой модели, если None то берем константу (только для посл задания)\n",
        "        \"\"\"\n",
        "          \n",
        "        loss_func = self.losses_dict[self.loss]\n",
        "        obj_sample_size = int(np.round(self.subsample * X.shape[0]))\n",
        "        cols_sample_size = int(np.round(self.colsample * X.shape[1]))\n",
        "\n",
        "        self.models = []\n",
        "        self.features = []\n",
        "\n",
        "        if init_model is None:\n",
        "          y_pred = 0\n",
        "          self.startModel = None\n",
        "        else:\n",
        "          self.startModel = init_model()\n",
        "          self.startModel.fit(X, y)\n",
        "          y_pred = self.startModel.predict(X)\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "          estimator = base_model(*self.args, **self.kwargs)\n",
        "          grad = loss_func(y, y_pred)\n",
        "          x_train_size = np.array(sample(range(X.shape[0]), obj_sample_size))\n",
        "          cols = np.array(sample(range(X.shape[1]), cols_sample_size))\n",
        "          estimator.fit(X[x_train_size[:, np.newaxis], cols], grad[x_train_size])\n",
        "          y_pred += self.learning_rate * estimator.predict(X[:, cols])\n",
        "          self.models.append(estimator)\n",
        "          self.features.append(cols)\n",
        "        \n",
        "\n",
        "\n",
        "        \n",
        "    def predict(self, X):\n",
        "      if self.startModel is None:\n",
        "        y_pred = 0\n",
        "      else:\n",
        "        y_pred = self.startModel.predict(X)\n",
        "      for model, feature in zip(self.models, self.features):\n",
        "        y_pred += self.learning_rate * model.predict(X[:, feature])\n",
        "\n",
        "      if self.loss == 'mse':       \n",
        "            return np.around(y_pred).astype(int)\n",
        "      else:\n",
        "            return np.where(y_pred>=0, 1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "pejR1ZDMA7OC"
      },
      "outputs": [],
      "source": [
        "my_clf = MyGradientBoostingClassifier()\n",
        "clf = GradientBoostingClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VsYWNlsA7OD",
        "outputId": "b93d84bb-8e96-46e5-b7ec-530c4393fc81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "wine = load_wine()\n",
        "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)\n",
        "\n",
        "my_clf = MyGradientBoostingClassifier()\n",
        "clf = GradientBoostingClassifier()\n",
        "\n",
        "my_clf.fit(X_train, y_train, base_model = DecisionTreeRegressor)\n",
        "clf.fit(X_train, y_train)\n",
        "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
        "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQgm-1MLA7OD"
      },
      "source": [
        "## Подбираем параметры (2 балла)\n",
        "\n",
        "Давайте попробуем применить Ваш бустинг для предсказаний цены домов в Калифорнии. Чтобы можно было попробовтаь разные функции потерь, переведем по порогу таргет в 2 класса: дорогие и дешевые дома."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf8Ch-xEA7OE"
      },
      "source": [
        "В задании нужно\n",
        "\n",
        "1) Построить график точности в зависимости от числа итераций на валидации.\n",
        "\n",
        "2) Подобрать оптимальные параметры Вашего бустинга на валидации. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "1VBcuVDsA7OE"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "X, y = fetch_california_housing(return_X_y=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ro4PdRhA7OE",
        "outputId": "c7b36b4b-18da-44dd-817e-c28b3241ca47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20640, 8) (20640,)\n"
          ]
        }
      ],
      "source": [
        "# Превращаем регрессию в классификацию\n",
        "y = (y > 2.0).astype(int)\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "collapsed": true,
        "id": "BV3P0ND7A7OF"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "collapsed": true,
        "id": "QWV2IDDaA7OF"
      },
      "outputs": [],
      "source": [
        "my_clf = MyGradientBoostingClassifier(n_estimators=2000)\n",
        "my_clf.fit(X_train, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = []\n",
        "y_pred = 0\n",
        "for model, cols in zip(my_clf.models, my_clf.features):\n",
        "        y_pred += my_clf.learning_rate * model.predict(X_test[:, cols])\n",
        "        accuracy.append(accuracy_score(y_pred = np.round(y_pred).astype(int),\n",
        "                                                        y_true=y_test))"
      ],
      "metadata": {
        "id": "YIqJbgapRIpc"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "cvX9g9I0SpdZ"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(1, 2001), accuracy, linewidth = 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "iWSJ54fDSwEI",
        "outputId": "c3aef1e3-29d1-4d40-9fa4-1ceefb712936"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5a796e7310>]"
            ]
          },
          "metadata": {},
          "execution_count": 161
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNkYn7cbURZe",
        "outputId": "38966379-d3d0-4273-b7ad-d8dd3a8d2aba"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8393895348837209"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.xlabel(\"Кол-во моделей\")\n",
        "plt.plot(range(1, 11), accuracy[:10], linewidth = 3)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "3wJrTLxEUXSp",
        "outputId": "de17ee4a-e83c-426c-bdb8-22fb9be6cd3b"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Достаточно 4 моделей для максимальной точности."
      ],
      "metadata": {
        "id": "k3UFNvPuVGdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# У нас y - [0, 1], сделаем [-1, 1]"
      ],
      "metadata": {
        "id": "RL-f5NrnddUy"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GridSearch:\n",
        "\n",
        "  def __init__(self, losses, cols_sample, sub_samples):\n",
        "    self.n_estimators =  15\n",
        "    self.losses = losses\n",
        "    self.cols_sample = cols_sample\n",
        "    self.sub_samples = sub_samples\n",
        "    self.max_accuracy = -1\n",
        "  def findParams(self, X_train, y_train, X_test, y_test):\n",
        "    logger = {'loss' : 'mse',\n",
        "              'colsample' : 0,\n",
        "              'subsample' :0,\n",
        "              'n_estimators' : self.n_estimators}\n",
        "\n",
        "    for loss in self.losses:\n",
        "      for cols_s in self.cols_sample:\n",
        "        for sub_s in self.sub_samples:\n",
        "          my_clf = MyGradientBoostingClassifier(n_estimators=self.n_estimators, \n",
        "                                                loss = loss, colsample = cols_s,\n",
        "                                                subsample = sub_s)\n",
        "          if loss == 'mse':\n",
        "            my_clf.fit(X_train, y_train)\n",
        "            accuracy_pred = accuracy_score(my_clf.predict(X_test), y_test)\n",
        "          else:\n",
        "            my_clf.fit(X_train, 2 * y_train -1 ) #[0, 1] -> [-1, 1]\n",
        "            accuracy_pred = accuracy_score(my_clf.predict(X_test), 2 * y_test -1)\n",
        "\n",
        "          if accuracy_pred > self.max_accuracy:\n",
        "            logger['loss'] = loss\n",
        "            logger['colsample'] = cols_s\n",
        "            logger['subsample'] = sub_s\n",
        "            self.max_accuracy =  accuracy_pred\n",
        "    return logger, self.max_accuracy\n"
      ],
      "metadata": {
        "id": "60PcqhiHVaW7"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GsV = GridSearch(losses = ['logloss', 'mse', 'exploss'],\n",
        "                 cols_sample = np.linspace(0.2, 1, 5),\n",
        "                 sub_samples = np.linspace(0.2, 1, 5))"
      ],
      "metadata": {
        "id": "fTO0YdDYWw2u"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params, accuracy  = GsV.findParams(X_train, y_train, X_test ,y_test)"
      ],
      "metadata": {
        "id": "wbqbTQ3eXGP4"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xz4eNnAZdRX4",
        "outputId": "589b7db5-549b-4d22-f49a-11ca4e723017"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 'logloss', 'colsample': 0.8, 'subsample': 0.8, 'n_estimators': 15}"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSHAYUd3f9DU",
        "outputId": "bfad7d07-51e6-4a68-f730-b9874212124a"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8943798449612403"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMS78HdHA7OF"
      },
      "source": [
        "## BooBag BagBoo (1 балл)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjn0kcLWA7OF"
      },
      "source": [
        "Попробуем объединить бустинг и бэгинг. Давайте\n",
        "\n",
        "1) в качестве базовой модели брать не дерево решений, а случайный лес (из sklearn)\n",
        "\n",
        "2) обучать N бустингов на бустрапированной выборке, а затем предикт усреднять"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfyscGPpA7OG"
      },
      "source": [
        "Попробуйте обе этих стратегии на данных из прошлого задания. Получилось ли улучшить качество? Почему?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "collapsed": true,
        "id": "SsxZB8gKA7OG"
      },
      "outputs": [],
      "source": [
        "my_clf = MyGradientBoostingClassifier(**best_params)\n",
        "my_clf.fit(X_train, 2 * y_train - 1, base_model = RandomForestRegressor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CXpGYPpA7OG",
        "outputId": "d8407d35-9bcc-48e0-fbee-5ffb2f83bc76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8955910852713178"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ],
      "source": [
        "accuracy_score(my_clf.predict(X_test), 2 * y_test -1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = 10\n",
        "\n",
        "bagging = []\n",
        "\n",
        "for i in range(N):\n",
        "    objects = np.random.randint(0, X_train.shape[0], X_train.shape[0])\n",
        "    my_clf = MyGradientBoostingClassifier(**best_params)\n",
        "    my_clf.fit(X_train[objects, :], (y_train * 2 - 1)[objects])\n",
        "    bagging.append(my_clf)\n",
        "\n"
      ],
      "metadata": {
        "id": "xpeX-hkgj0Ie"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = 0\n",
        "for model in bagging:\n",
        "  predicted += model.predict(X_test)"
      ],
      "metadata": {
        "id": "WYyMMshi6Ino"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = np.where(predicted >= 0, 1 ,-1)"
      ],
      "metadata": {
        "id": "8bUGL_l36STh"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(predicted, 2 * y_test -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ipaTtKU6Ws8",
        "outputId": "7d56530f-8429-4b5a-97fe-768a82e91991"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8921996124031008"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Данные методы не улучшили метрики. Для 1-го случая можно поиграться с гиперпараметрами RandomForest."
      ],
      "metadata": {
        "id": "tGRwt_d16ZXt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "eNH3tSoIA7OG"
      },
      "source": [
        "## Умная инициализация (1 балл)\n",
        "\n",
        "Попробуйте брать в качестве инициализации бустинга не константу, а какой-то алгоритм и уже от его предикта стартовать итерации бустинга. Попробуйте разные модели из sklearn: линейные модели, рандом форест, svm..\n",
        "\n",
        "Получилось ли улучшить качество? Почему?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "collapsed": true,
        "id": "zo2N0dEoA7OG"
      },
      "outputs": [],
      "source": [
        "base_models = [SVR, DecisionTreeRegressor, LinearRegression]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoVFde5WA7OG",
        "outputId": "30590e97-a1df-42f7-d517-088f6cb4a10a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVR : 0.7030038759689923\n",
            "DecisionTreeRegressor : 0.8357558139534884\n",
            "LinearRegression : 0.8873546511627907\n"
          ]
        }
      ],
      "source": [
        "for model in base_models:\n",
        "  my_clf = MyGradientBoostingClassifier(**best_params)\n",
        "  my_clf.fit(X_train, y_train * 2 - 1, init_model=model)\n",
        "  print(f\"{model.__name__} : {accuracy_score(my_clf.predict(X_test), y_test * 2 - 1)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### SVR и DecisionTreeRegressor ухудшили результаты, однако если опять же менять и их гиперпараметры, то возможно это может улучшить метрики."
      ],
      "metadata": {
        "id": "bIkx3P8F9aZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "%%shell\n",
        "jupyter nbconvert --to html /content/kirichenko_hw3.ipynb\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC5nmmXfCdFF",
        "outputId": "b13355b5-8d3f-4d12-9347-4de7b86039ef"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /content/kirichenko_hw3.ipynb to html\n",
            "[NbConvertApp] Writing 353291 bytes to /content/kirichenko_hw3.html\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78l8EGosA7OG"
      },
      "source": [
        "## Фидбек (бесценно)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrEKo9NpA7OH"
      },
      "source": [
        "* Какие аспекты обучения  ансамблей Вам показались непонятными? Какое место стоит дополнительно объяснить?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxhb52vCA7OH"
      },
      "source": [
        "### Ваш ответ здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYesswMhA7OH"
      },
      "source": [
        "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3vRd_kXA7OH"
      },
      "source": [
        "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "c8yY_2uyA7OH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "aWy8IvtVA7OI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}