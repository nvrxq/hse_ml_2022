{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxwOUXsBA7N6"
      },
      "source": [
        "### Машинное обучение\n",
        "## Домашнее задание №3 - Градиентный бустинг"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nnb6L4XbA7N8"
      },
      "source": [
        "**Общая информация**\n",
        "\n",
        "**Срок сдачи:** 16 февраля 2023, 08:30   \n",
        "**Штраф за опоздание:** -2 балла за каждые сутки\n",
        "\n",
        "Используйте данный Ipython Notebook при оформлении домашнего задания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOfGe85vA7N9"
      },
      "source": [
        "##  Считаем производные для функций потерь (1 балл)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MOTkXLJA7N9"
      },
      "source": [
        "Мы будем реализовать градиентный бустинг для 3 функций потерь:\n",
        "\n",
        "1) MSE  $L(a(x_i), y_i) = (y_i - a(x_i)) ^ 2$\n",
        "\n",
        "2) Экспоненциальная  $L(a(x_i), y_i) = exp( -a(x_i) y_i), y_i \\in \\{-1, 1\\}$\n",
        "\n",
        "3) Логистическая  $L(a(x_i), y_i) = \\log (1 + exp( -a(x_i) y_i)), y_i \\in \\{-1, 1\\}$\n",
        "\n",
        "где $a(x_i)$ предсказание бустинга на итом объекте. \n",
        "\n",
        "Для каждой функции потерь напишите таргет, на который будет настраиваться каждое дерево в бустинге. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1a_m5WeA7N-"
      },
      "source": [
        "Ваше решение тут"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx6deysjA7N-"
      },
      "source": [
        "1)mse : $$2 *(y - a)$$\n",
        "2)exp : $$\\exp(-a(x)y) * y $$\n",
        "3)logloss : $$\\frac{1}{1 + \\exp(-a(x)y)} * (exp(-a(xi)y) * y)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O6s_gZsA7N_"
      },
      "source": [
        "##  Реализуем градиентный бустинг (3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LB5WZ9UaA7N_"
      },
      "source": [
        "Реализуйте класс градиентного бустинга для классификации. Ваша реализация бустинга должна работать по точности не более чем на 5 процентов хуже чем GradientBoostingClassifier из sklearn. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc8vCbKJA7OA"
      },
      "source": [
        "Детали реализации:\n",
        "\n",
        "-- должно поддерживаться 3 функции потерь\n",
        "\n",
        "-- сами базовые алгоритмы(деревья, линейные модели и тп) реализовать не надо, просто возьмите готовые из sklearn\n",
        "\n",
        "-- в качестве функции потерь для построения одного дерева используйте MSE\n",
        "\n",
        "-- шаг в бустинге можно не подбирать, можно брать константный\n",
        "\n",
        "-- можно брать разные модели в качестве инициализации бустинга\n",
        "\n",
        "-- должны поддерживаться следующие параметры:\n",
        "\n",
        "а) число итераций\n",
        "б) размер шага\n",
        "в) процент случайных фичей при построении одного дерева\n",
        "д) процент случайных объектов при построении одного дерева\n",
        "е) параметры базового алгоритма (передавайте через **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "collapsed": true,
        "id": "ts0v-wnQA7OB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from random import sample\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "collapsed": true,
        "id": "wtZdl2A0A7OB"
      },
      "outputs": [],
      "source": [
        "class MyGradientBoostingClassifier:\n",
        "\n",
        "    def __init__(self, loss='mse', \n",
        "                 learning_rate=0.1, \n",
        "                 n_estimators=50, \n",
        "                 colsample=1.0, \n",
        "                 subsample=1.0, \n",
        "                 *args, **kwargs):\n",
        "        \"\"\"\n",
        "        loss -- один из 3 лоссов:\n",
        "        learning_rate -- шаг бустинга\n",
        "        n_estimators -- число итераций\n",
        "        colsample -- процент рандомных признаков при обучнеии одного алгоритма\n",
        "        subsample -- процент рандомных объектов при обучнеии одного алгоритма\n",
        "        args, kwargs -- параметры  базовых моделей\n",
        "        \"\"\"\n",
        "        # Ваш код здесь\n",
        "        self.loss = loss\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_estimators = n_estimators\n",
        "        self.colsample = colsample\n",
        "        self.subsample = subsample\n",
        "        self.args = args\n",
        "        self.kwargs = kwargs\n",
        "        self.losses_dict = {\n",
        "            'mse' : self.mse_grad,\n",
        "            'exploss' : self.exp_grad,\n",
        "            'logloss' : self.logLoss_grad\n",
        "        }\n",
        "    \n",
        "\n",
        "    def mse_grad(self, y_true, y_pred):\n",
        "      return 2 * (y_true - y_pred)\n",
        "\n",
        "    def exp_grad(self, y_true, y_pred):\n",
        "      return np.exp(y_true * -y_pred) * y_true\n",
        "      \n",
        "   \n",
        "    def logLoss_grad(self, y_true, y_pred):\n",
        "      exp_ = np.exp(y_pred * y_true)\n",
        "      return y_true / (1 + exp_)\n",
        "\n",
        "\n",
        "    def fit(self, X, y, base_model = DecisionTreeRegressor, init_model=None):\n",
        "        \"\"\"\n",
        "        X -- объекты для обучения:\n",
        "        y -- таргеты для обучения\n",
        "        base_model -- класс базовых моделей, например sklearn.tree.DecisionTreeRegressor\n",
        "        init_model -- класс для первой модели, если None то берем константу (только для посл задания)\n",
        "        \"\"\"\n",
        "          \n",
        "        loss_func = self.losses_dict[self.loss]\n",
        "        obj_sample_size = int(np.round(self.subsample * X.shape[0]))\n",
        "        cols_sample_size = int(np.round(self.colsample * X.shape[1]))\n",
        "\n",
        "        self.models = []\n",
        "        self.features = []\n",
        "\n",
        "        if init_model is None:\n",
        "          y_pred = 0\n",
        "          self.startModel = None\n",
        "        else:\n",
        "          self.startModel = init_model()\n",
        "          self.startModel.fit(X, y)\n",
        "          y_pred = self.startModel.predict(X)\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "          estimator = base_model(*self.args, **self.kwargs)\n",
        "          grad = loss_func(y, y_pred)\n",
        "          x_train_size = np.array(sample(range(X.shape[0]), obj_sample_size))\n",
        "          cols = np.array(sample(range(X.shape[1]), cols_sample_size))\n",
        "          estimator.fit(X[x_train_size[:, np.newaxis], cols], grad[x_train_size])\n",
        "          y_pred += self.learning_rate * estimator.predict(X[:, cols])\n",
        "          self.models.append(estimator)\n",
        "          self.features.append(cols)\n",
        "        \n",
        "\n",
        "\n",
        "        \n",
        "    def predict(self, X):\n",
        "      if self.startModel is None:\n",
        "        y_pred = 0\n",
        "      else:\n",
        "        y_pred = self.startModel.predict(X)\n",
        "      for model, feature in zip(self.models, self.features):\n",
        "        y_pred += self.learning_rate * model.predict(X[:, feature])\n",
        "\n",
        "      if self.loss == 'mse':       \n",
        "            return np.around(y_pred).astype(int)\n",
        "      else:\n",
        "            return np.where(y_pred>=0, 1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "pejR1ZDMA7OC"
      },
      "outputs": [],
      "source": [
        "my_clf = MyGradientBoostingClassifier()\n",
        "clf = GradientBoostingClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VsYWNlsA7OD",
        "outputId": "4321d0ce-fc49-4f9b-bf92-ece323b08ab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "wine = load_wine()\n",
        "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)\n",
        "\n",
        "my_clf = MyGradientBoostingClassifier()\n",
        "clf = GradientBoostingClassifier()\n",
        "\n",
        "my_clf.fit(X_train, y_train, base_model = DecisionTreeRegressor)\n",
        "clf.fit(X_train, y_train)\n",
        "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
        "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQgm-1MLA7OD"
      },
      "source": [
        "## Подбираем параметры (2 балла)\n",
        "\n",
        "Давайте попробуем применить Ваш бустинг для предсказаний цены домов в Калифорнии. Чтобы можно было попробовтаь разные функции потерь, переведем по порогу таргет в 2 класса: дорогие и дешевые дома."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf8Ch-xEA7OE"
      },
      "source": [
        "В задании нужно\n",
        "\n",
        "1) Построить график точности в зависимости от числа итераций на валидации.\n",
        "\n",
        "2) Подобрать оптимальные параметры Вашего бустинга на валидации. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "1VBcuVDsA7OE"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "X, y = fetch_california_housing(return_X_y=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ro4PdRhA7OE",
        "outputId": "f975bbcc-fc83-46ad-ef42-a4461c43628f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20640, 8) (20640,)\n"
          ]
        }
      ],
      "source": [
        "# Превращаем регрессию в классификацию\n",
        "y = (y > 2.0).astype(int)\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "collapsed": true,
        "id": "BV3P0ND7A7OF"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "collapsed": true,
        "id": "QWV2IDDaA7OF"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "my_clf = MyGradientBoostingClassifier(n_estimators=2000)\n",
        "my_clf.fit(X_train, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = []\n",
        "count = 1\n",
        "y_pred = 0\n",
        "for model, cols in zip(my_clf.models, my_clf.features):\n",
        "        y_pred += my_clf.learning_rate * model.predict(X_test[:, cols])\n",
        "        accuracy.append(accuracy_score(y_pred = np.round(y_pred).astype(int),\n",
        "                                                        y_true=y_test))"
      ],
      "metadata": {
        "id": "YIqJbgapRIpc"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "cvX9g9I0SpdZ"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(1, 2001), accuracy, linewidth = 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "iWSJ54fDSwEI",
        "outputId": "981edc6a-e9df-4dc6-e85c-97d64cd58b6d"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5a7980dcd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNkYn7cbURZe",
        "outputId": "bf2b9f8b-74c7-4710-b5e5-5473cbeb2c03"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8372093023255814"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.xlabel(\"Кол-во моделей\")\n",
        "plt.plot(range(1, 11), accuracy[:10], linewidth=3)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "3wJrTLxEUXSp",
        "outputId": "49c06eb1-d71a-4778-f9b9-cdda3cf663a1"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Достаточно 4 моделей для максимальной точности."
      ],
      "metadata": {
        "id": "k3UFNvPuVGdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# У нас y - [0, 1], сделаем [-1, 1]"
      ],
      "metadata": {
        "id": "RL-f5NrnddUy"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GridSearch:\n",
        "\n",
        "  def __init__(self, losses, cols_sample, sub_samples):\n",
        "    self.n_estimators =  15\n",
        "    self.losses = losses\n",
        "    self.cols_sample = cols_sample\n",
        "    self.sub_samples = sub_samples\n",
        "    self.max_accuracy = -1\n",
        "  def findParams(self, X_train, y_train, X_test, y_test):\n",
        "    logger = {'loss' : 'mse',\n",
        "              'colsample' : 0,\n",
        "              'subsample' :0,\n",
        "              'n_estimators' : self.n_estimators}\n",
        "\n",
        "    for loss in self.losses:\n",
        "      for cols_s in self.cols_sample:\n",
        "        for sub_s in self.sub_samples:\n",
        "          my_clf = MyGradientBoostingClassifier(n_estimators=self.n_estimators, \n",
        "                                                loss = loss, colsample = cols_s,\n",
        "                                                subsample = sub_s)\n",
        "          if loss == 'mse':\n",
        "            my_clf.fit(X_train, y_train)\n",
        "            accuracy_pred = accuracy_score(my_clf.predict(X_test), y_test)\n",
        "          else:\n",
        "            my_clf.fit(X_train, 2 * y_train -1 ) #[0, 1] -> [-1, 1]\n",
        "            accuracy_pred = accuracy_score(my_clf.predict(X_test), 2 * y_test -1)\n",
        "\n",
        "          if accuracy_pred > self.max_accuracy:\n",
        "            logger['loss'] = loss\n",
        "            logger['colsample'] = cols_s\n",
        "            logger['subsample'] = sub_s\n",
        "            self.max_accuracy =  accuracy_pred\n",
        "    return logger, self.max_accuracy\n"
      ],
      "metadata": {
        "id": "60PcqhiHVaW7"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GsV = GridSearch(losses = ['exploss', 'mse', 'logloss'],\n",
        "                 cols_sample = np.linspace(0.2, 1, 5),\n",
        "                 sub_samples = np.linspace(0.2, 1, 5))"
      ],
      "metadata": {
        "id": "fTO0YdDYWw2u"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params, accuracy  = GsV.findParams(X_train, y_train, X_test ,y_test)"
      ],
      "metadata": {
        "id": "wbqbTQ3eXGP4"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xz4eNnAZdRX4",
        "outputId": "4c80116a-720f-4c12-9b14-5b1c3cb630dd"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 'logloss', 'colsample': 0.8, 'subsample': 0.8, 'n_estimators': 15}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSHAYUd3f9DU",
        "outputId": "fb63ef74-2b83-4b68-8695-627467ac0e3c"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8955910852713178"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMS78HdHA7OF"
      },
      "source": [
        "## BooBag BagBoo (1 балл)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjn0kcLWA7OF"
      },
      "source": [
        "Попробуем объединить бустинг и бэгинг. Давайте\n",
        "\n",
        "1) в качестве базовой модели брать не дерево решений, а случайный лес (из sklearn)\n",
        "\n",
        "2) обучать N бустингов на бустрапированной выборке, а затем предикт усреднять"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfyscGPpA7OG"
      },
      "source": [
        "Попробуйте обе этих стратегии на данных из прошлого задания. Получилось ли улучшить качество? Почему?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "collapsed": true,
        "id": "SsxZB8gKA7OG"
      },
      "outputs": [],
      "source": [
        "my_clf = MyGradientBoostingClassifier(**best_params)\n",
        "my_clf.fit(X_train, 2 * y_train - 1, base_model = RandomForestRegressor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CXpGYPpA7OG",
        "outputId": "702c4412-87d7-4ce3-db87-254c40c8d97f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8987403100775194"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "accuracy_score(my_clf.predict(X_test), 2 * y_test -1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = 10\n",
        "\n",
        "bagging = []\n",
        "\n",
        "for i in range(N):\n",
        "    objects = np.random.randint(0, X_train.shape[0], X_train.shape[0])\n",
        "    my_clf = MyGradientBoostingClassifier(**best_params)\n",
        "    my_clf.fit(X_train[objects, :], (y_train * 2 - 1)[objects])\n",
        "    bagging.append(my_clf)\n",
        "\n"
      ],
      "metadata": {
        "id": "xpeX-hkgj0Ie"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = 0\n",
        "for model in bagging:\n",
        "  predicted += model.predict(X_test)"
      ],
      "metadata": {
        "id": "WYyMMshi6Ino"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = np.where(predicted >= 0, 1 ,-1)"
      ],
      "metadata": {
        "id": "8bUGL_l36STh"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(predicted, 2 * y_test -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ipaTtKU6Ws8",
        "outputId": "29f6a7ab-f39a-4b60-d926-604aa8c3dcc0"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8895348837209303"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Данные методы не улучшили метрики. Для 1-го случая можно поиграться с гиперпараметрами RandomForest."
      ],
      "metadata": {
        "id": "tGRwt_d16ZXt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "eNH3tSoIA7OG"
      },
      "source": [
        "## Умная инициализация (1 балл)\n",
        "\n",
        "Попробуйте брать в качестве инициализации бустинга не константу, а какой-то алгоритм и уже от его предикта стартовать итерации бустинга. Попробуйте разные модели из sklearn: линейные модели, рандом форест, svm..\n",
        "\n",
        "Получилось ли улучшить качество? Почему?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "collapsed": true,
        "id": "zo2N0dEoA7OG"
      },
      "outputs": [],
      "source": [
        "base_models = [SVR, DecisionTreeRegressor, LinearRegression]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoVFde5WA7OG",
        "outputId": "5f743bcf-0c36-40f6-f5b1-948afb861739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVR : 0.7223837209302325\n",
            "DecisionTreeRegressor : 0.8321220930232558\n",
            "LinearRegression : 0.8888081395348837\n"
          ]
        }
      ],
      "source": [
        "for model in base_models:\n",
        "  my_clf = MyGradientBoostingClassifier(**best_params)\n",
        "  my_clf.fit(X_train, y_train * 2 - 1, init_model=model)\n",
        "  print(f\"{model.__name__} : {accuracy_score(my_clf.predict(X_test), y_test * 2 - 1)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### SVR и DecisionTreeRegressor ухудшили результаты, однако если опять же менять и их гиперпараметры, то возможно это может улучшить метрики."
      ],
      "metadata": {
        "id": "bIkx3P8F9aZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "%%shell\n",
        "jupyter nbconvert --to html /content/kirichenko_hw3.ipynb\n",
        "\n"
      ],
      "metadata": {
        "id": "dC5nmmXfCdFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78l8EGosA7OG"
      },
      "source": [
        "## Фидбек (бесценно)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrEKo9NpA7OH"
      },
      "source": [
        "* Какие аспекты обучения  ансамблей Вам показались непонятными? Какое место стоит дополнительно объяснить?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxhb52vCA7OH"
      },
      "source": [
        "### Ваш ответ здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYesswMhA7OH"
      },
      "source": [
        "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3vRd_kXA7OH"
      },
      "source": [
        "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "c8yY_2uyA7OH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "aWy8IvtVA7OI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}